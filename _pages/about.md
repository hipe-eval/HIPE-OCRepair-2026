---
title: HIPE-2026 Shared Task
permalink: about
---

### HIPE-2026: Evaluating Accurate and Efficient Person–Place Relation Extraction

Building on the success of HIPE-2020 and HIPE-2022, the third edition of the HIPE shared
task explores the extraction of **person–place relations** in **multilingual historical
documents**. Participants will develop systems that help uncover implicit and explicit
connections between people and places across time, contributing to research in
historical knowledge graphs, spatial humanities, and biographical reconstruction.

<div style="text-align: center;">
  <img src="/HIPE-2026/assets/images/hipe-2026-motivation.png" alt="Motivation" />
</div>

#### Challenges of the task

Traditional simple co-occurence analysis is not good enough!
![Example](/HIPE-2026/assets/images/churchill-hipe-2026-example.png)

Systems must understand the text to determine whether a person was actually at a place, and if so, whether this was in the
immediate temporal context of the document's publication time, or at some point in the past. This requires handling
historical language variation, OCR noise, and limited context, as well as reasoning about
temporal and geographical information.

For full details on task setup, data, and evaluation criteria, please see the [Tasks & Data](/HIPE-2026/tasks) page.

---

### Evaluation Profiles

HIPE-2026 features two evaluation profiles:

1. **Accuracy Profile** – Focusing on system performance in relation classification.
2. **Efficiency Profile** – Rewarding scalable, lightweight approaches considering model size and compute cost.

An unseen dataset from a different domain will be included to test generalization.

---

### Registration and Information

More information on the schedule and registration can be found on the [CLEF page](https://clef2026.clef-initiative.eu/). For questions, please contact the organizers via our [mailing list](https://groups.google.com/g/hipe-2026).

---

### About the Previous Edition (HIPE-2022)

HIPE-2022 expanded the HIPE evaluation series by introducing multilingual corpora, more complex document types, and diverse annotation tagsets. Participants were challenged to build systems that could cope with OCR noise, partial knowledge base coverage, and historical language variation. See the [HIPE-2022 website](https://impresso.github.io/CLEF-HIPE-2022/) for details.

---
